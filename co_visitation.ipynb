{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_of_sessions_to_use = 1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_parquet('../data/train.parquet')\n",
    "test = pd.read_parquet('../data/test.parquet')\n",
    "\n",
    "sample_sub = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "if fraction_of_sessions_to_use != 1:\n",
    "    lucky_sessions_train = train.drop_duplicates(['session']).sample(frac=fraction_of_sessions_to_use, random_state=42)['session']\n",
    "    subset_of_train = train[train.session.isin(lucky_sessions_train)]\n",
    "    \n",
    "    lucky_sessions_test = test.drop_duplicates(['session']).sample(frac=fraction_of_sessions_to_use, random_state=42)['session']\n",
    "    subset_of_test = test[test.session.isin(lucky_sessions_test)]\n",
    "else:\n",
    "    subset_of_train = train\n",
    "    subset_of_test = test\n",
    "\n",
    "subset_of_train.index = pd.MultiIndex.from_frame(subset_of_train[['session']])\n",
    "subset_of_test.index = pd.MultiIndex.from_frame(subset_of_test[['session']])\n",
    "\n",
    "chunk_size = 30_000\n",
    "min_ts = train.ts.min()\n",
    "max_ts = test.ts.max()\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "next_AIDs = defaultdict(Counter)\n",
    "\n",
    "subsets = pd.concat([subset_of_train, subset_of_test])\n",
    "sessions = subsets.session.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subsets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mlen\u001b[39m(subsets)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'subsets' is not defined"
     ]
    }
   ],
   "source": [
    "len(subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, sessions.shape[0], chunk_size):\n",
    "    current_chunk = subsets.loc[sessions[i]:sessions[min(sessions.shape[0]-1, i+chunk_size-1)]].reset_index(drop=True)\n",
    "    current_chunk = current_chunk.groupby('session', as_index=False).nth(list(range(-30,0))).reset_index(drop=True)\n",
    "    consecutive_AIDs = current_chunk.merge(current_chunk, on='session')\n",
    "    consecutive_AIDs = consecutive_AIDs[consecutive_AIDs.aid_x != consecutive_AIDs.aid_y]\n",
    "    consecutive_AIDs['days_elapsed'] = (consecutive_AIDs.ts_y - consecutive_AIDs.ts_x) / (24 * 60 * 60)\n",
    "    consecutive_AIDs = consecutive_AIDs[(consecutive_AIDs.days_elapsed >= 0) & (consecutive_AIDs.days_elapsed <= 1)]\n",
    "    \n",
    "    for aid_x, aid_y in zip(consecutive_AIDs['aid_x'], consecutive_AIDs['aid_y']):\n",
    "        next_AIDs[aid_x][aid_y] += 1\n",
    "    \n",
    "del train, subset_of_train, subsets\n",
    "\n",
    "session_types = ['clicks', 'carts', 'orders']\n",
    "test_session_AIDs = test.reset_index(drop=True).groupby('session')['aid'].apply(list)\n",
    "test_session_types = test.reset_index(drop=True).groupby('session')['type'].apply(list)\n",
    "\n",
    "labels = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sessions that we did not manage to extend based on the co-visitation matrix: 828\n"
     ]
    }
   ],
   "source": [
    "no_data = 0\n",
    "no_data_all_aids = 0\n",
    "type_weight_multipliers = {0: 1, 1: 6, 2: 3}\n",
    "for AIDs, types in zip(test_session_AIDs, test_session_types):\n",
    "    \n",
    "    AIDs = list(dict.fromkeys(AIDs[::-1]))\n",
    "    AIDs_len_start = len(AIDs)\n",
    "        \n",
    "    candidates = []\n",
    "    for AID in AIDs:\n",
    "        if AID in next_AIDs: candidates += [aid for aid, count in next_AIDs[AID].most_common(20)]\n",
    "    AIDs += [AID for AID, cnt in Counter(candidates).most_common(40) if AID not in AIDs]\n",
    "        \n",
    "    labels.append(AIDs[:20])\n",
    "    if candidates == []: no_data += 1\n",
    "    if AIDs_len_start == len(AIDs): no_data_all_aids += 1\n",
    "\n",
    "# >>> outputting results to CSV\n",
    "\n",
    "labels_as_strings = [' '.join([str(l) for l in lls]) for lls in labels]\n",
    "\n",
    "predictions = pd.DataFrame(data={'session_type': test_session_AIDs.index, 'labels': labels_as_strings})\n",
    "\n",
    "prediction_dfs = []\n",
    "\n",
    "for st in session_types:\n",
    "    modified_predictions = predictions.copy()\n",
    "    modified_predictions.session_type = modified_predictions.session_type.astype('str') + f'_{st}'\n",
    "    prediction_dfs.append(modified_predictions)\n",
    "\n",
    "submission = pd.concat(prediction_dfs).reset_index(drop=True)\n",
    "submission.to_csv('submission_matrix_only.csv', index=False)\n",
    "\n",
    "print(f'Test sessions that we did not manage to extend based on the co-visitation matrix: {no_data_all_aids}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edfeea400d81ca3feef2d2b2500044129aae7aa2fb1143256c7581b461022992"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
